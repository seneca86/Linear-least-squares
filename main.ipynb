{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares fit\n",
    "### Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to estimate the slope of the relationship between two variables; the most common is a linear least squares fit. A linear fit is a line intended to model the relationship between variables. A least squares fit is one that minimizes the mean squared error (MSE) between the line and the data.\n",
    "\n",
    "Suppose we have a sequence of points, `ys`, that we want to express as a function of another sequence `xs`. If there is a linear relationship between xs and ys with intercept inter and slope slope, we expect:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "y[i] = inter + slope * x[i]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But unless the correlation is perfect, there is a deviation from the line, or residual:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "res = ys - (inter + slope * xs)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might try to minimize the absolute value of the residuals, or their squares, or their cubes; but the most common choice is to minimize the sum of squared residuals, `sum(res**2)`, because:\n",
    "\n",
    "* Squaring treats positive and negative residuals the same\n",
    "\n",
    "* Squaring gives more weight to large residuals\n",
    "\n",
    "* If the residuals are uncorrelated and normally distributed with mean 0 and constant (but unknown) variance, then the least squares fit is also the maximum likelihood estimator of inter and slope. See [link](https://en.wikipedia.org/wiki/Linear_regression)\n",
    "\n",
    "* The values of inter and slope that minimize the squared residuals can be computed efficiently\n",
    "\n",
    "If you are using xs to predict values of ys, guessing too high might be better (or worse) than guessing too low. In that case you might want to compute some cost function for each residual, and minimize total cost, sum(cost(res)). However, computing a least squares fit is quick, easy and often good enough."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load a few libraries that we will need for our calculations and plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 150\n",
    "sns.set_theme()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('.lesson/assets/FemPreg.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can define our own `LeastSquares` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeastSquares(xs, ys):\n",
    "    mean_x = np.mean(xs)\n",
    "    var_x = np.var(xs)\n",
    "    mean_y = np.mean(ys)\n",
    "    cov = np.dot(xs - mean_x, ys - mean_y) / len(xs)\n",
    "    slope = cov / var_x\n",
    "    inter = mean_y - slope * mean_x\n",
    "    return inter, slope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LeastSquares` takes sequences `xs` and `ys` and returns the estimated parameters inter and slope. For details on how it works, see [here](https://en.wikipedia.org/wiki/Numerical_methods_for_linear_least_squares)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already apply the function to our dataset, if we first remove the `NAs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = 6.830396973311053, slope = 0.017453851471802718\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "inter, slope = LeastSquares(df.agepreg, df.totalwgt_lb)\n",
    "print(f'intercept = {inter}, slope = {slope}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we have the parameters of the model, we define a function to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitLine(xs, inter, slope):\n",
    "    fit_xs = np.sort(xs)\n",
    "    fit_ys = inter + slope * fit_xs\n",
    "    return fit_xs, fit_ys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and apply it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.83, 10.91, 11.75, ..., 42.75, 43.  , 44.08])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_xs, fit_ys = FitLine(df.agepreg, inter, slope)\n",
    "fit_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.01942218, 7.02081849, 7.03547973, ..., 7.57654912, 7.58091259,\n",
       "       7.59976275])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated intercept and slope are $6.8$ lbs and $0.017$ lbs per year. These values are hard to interpret in this form: the intercept is the expected weight of a baby whose mother is 0 years old, which doesnâ€™t make sense in context, and the slope is too small to grasp easily. Let's organize everything in a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit = pd.DataFrame()\n",
    "df_fit['agepreg'] = fit_xs\n",
    "df_fit['totalwgt_lb'] = fit_ys\n",
    "df_fit['type'] = 'fit'\n",
    "\n",
    "df_train = df.loc[:,['agepreg', 'totalwgt_lb']]\n",
    "df_train['type'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
